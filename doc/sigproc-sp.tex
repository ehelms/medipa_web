% THIS IS SIGPROC-SP.TEX - VERSION 3.1
% WORKS WITH V3.2SP OF ACM_PROC_ARTICLE-SP.CLS
% APRIL 2009
%
% It is an example file showing how to use the 'acm_proc_article-sp.cls' V3.2SP
% LaTeX2e document class file for Conference Proceedings submissions.
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V3.2SP) *DOES NOT* produce:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) Page numbering
% ---------------------------------------------------------------------------------------------------------------
% It is an example which *does* use the .bib file (from which the .bbl file
% is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission,
% you need to 'insert'  your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% Questions regarding SIGS should be sent to
% Adrienne Griscti ---> griscti@acm.org
%
% Questions/suggestions regarding the guidelines, .tex and .cls files, etc. to
% Gerald Murray ---> murray@hq.acm.org
%
% For tracking purposes - this is V3.1SP - APRIL 2009

\documentclass{acm_proc_article-sp}

\begin{document}

\title{Medipa: Visualizing Medical Scans in 3D on the Web}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{2} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Juhee Bae\\
       \affaddr{North Carolina State University}\\
       \email{jbae3@ncsu.edu}
% 2nd. author
\alignauthor
Eric D. Helms\\
       \affaddr{North Carolina State University}\\
       \email{edhelms@ncsu.edu}
}
% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
\date{12 December 2011}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
\end{abstract}

\terms{WebGL, Medical}

\section{Introduction}


\section{3D Web Visualizations}

\section{Related Works}
The technique of volume rendering gained a lot of interest especially to investigate medical data. The process of volume rendering has several stages to produce the result image [Drebin et al. 1988]. First, the input volume data set is converted to a set of material percentage volumes. Each element in the volume is called a voxel (volume element) which the value represents the percentage of the material in a region of space. After classifying the dataset, a linear ramp called a transfer function assigns the opacity and color values to every voxel in the volume. It allows viewing a certain part of the volume by selecting a certain range of opacity and color. Next, the volume is projected to the image plane by compositing the opacity and colors of the voxels.
Previous researches attempted multiple methods to visualize volumes. Marching cubes [Lorensen 1987] provided an algorithm that creates polygonal representation of iso-surfaces from a three dimensional array of data. It uses a table of possible edge intersections of a cube which describes how a surface cuts the surface. For realism, it calculates the normalized gradient from the original data which helps to create the desired surface model. However, the drawback of the algorithm is the speed regarding to the great number of triangles and overhead by rotation. The amount of memory needed for the surface result is another problem. Also, there is a ‘hole problem’ when at least one cube face has an intersection point in each of its four edges.
[Levoy 1990] introduced an efficient way to use ray-tracing for volume rendering. It improves its performance by employing binary volumes of coherent regions and adaptively terminating ray-tracing at the user-selected opacity threshold. However, the method is not interactive.
For interactivity, splatting provided a way to perform volume rendering in parallel. It is a technique that splats every voxel to the viewing surface in back-to-front order as if throwing a snow ball to a wall [Westover 1991]. This method runs in parallel, thus reduces the rendering time, but produces respectively lower image qualities. 


\section{Concept}
\subsection{Rendering algorithm}

Volume rendering displays a 3D scalar field to a 3D image. The two traditional ways are slice-based rendering and volume ray tracing. Our algorith follows volume ray tracing that shoots rays through the volume and samples along the path by equal intervals. As the rays are sampled through the volume, the scalar density values are integrated based on the opacity and RGB values from the transfer function. By the use of transfer function, it shows the corresponding emission and absorption of light for the sample point. The advantages of ray tracing are optimization from empty space skipping, independence of the projection view, and easiness of development.
We refered to an interactive volume renderer using HTML5. The rendering algorithm bases on ray tracing and applies RGB and alpha input values from the transfer function to the texture images. A transfer function assigns RGBA values to each voxel in the volume. Its main purpose is to observe a specific part of the volume. We allowed visual controls of the transfer function to manipulate the RGB and alpha values. 

The algorithm uses shaders to render the model and allows the number of samples of steps throughout the ray. The general approach of ray tracing on a volume is to apply bounding box or a cube to the volume since it is faster to render it with knowing a start and stop points for the rays. In order to provide faster performace, the algorithm renders the position of front and back facing triangles to the textures. The position of the triangles mapped to the texture coordinates from the front and back face triangles easily gives the starting and finishing points of the ray. Then, starting from the start point of each ray, we accumulate the color and opacity by compositing the collected samples in front-to-back direction. The process is applied to the shader as below.

\begin{verbatim}
vec3 raystart = v_PosLocal;
vec2 texcoords = (v_Position.xy / v_Position.w + vec2(1.0, 1.0)) / 2.0;
vec3 rayend = texture2D(backpos_tex, texcoords).xyz;
vec3 raydir = rayend - raystart;
vec3 deltadir = normalize(raydir) * stepsize;
float len = length(raydir);
float deltadirlen = length(deltadir);
vec3 raypos = raystart + steps * interstep * deltadir;
float lengthsum = steps * interstep * deltadirlen;
vec4 colorsum = mix(vec4(0.0, 0.0, 0.0, 0.0), texture2D(intermediate_tex, texcoords), clamp(interstep, 0.0, 1.0));
vec4 colorsample;
for (float i = 0.0; i < steps; i += 1.0)
{
if (lengthsum >= len || colorsum.a >= 1.0) break;
colorsample = tex3D(raypos);
colorsample.a *= stepsize * opacity;
colorsum.rgb += colorsample.rgb * colorsample.a * (1.0 - colorsum.a);
colorsum.a += colorsample.a * (1.0 - colorsum.a);
raypos += deltadir;
lengthsum += deltadirlen;
}
gl_FragColor = mix(colorsum, vec4(colorsum.rgb * clamp(colorsum.a, 0.0, 1.0) * brightness, 1.0), finalstep);
\end{verbatim}

\section{Medipa}
The Medipa system was designed in order to allow users to upload medical image scans in their native formats.

\subsection{Architecture}
The underlying system was designed as a web-based Model-View-Controller (MVC) pattern with a data processing layer server side and all rendering happening within the user's browser.  The architecture can be seen in Figure.

\subsection{Data Processing}
Most medical image scans come in a binary format that can not be directly ported to WebGL for rendering.  Given this limitation, a small data processing library was created taking advantage of SimpleITK.  SimpleITK is a library that can turn binary format medical scans into data representations that can be worked on within native code.  The layer would take in the binary medical scan format, process with SimpleITK and then turn the outputted pixel data array into a series of PNG's that represented each layer of the scan.  The subsequent PNG is saved down to the file system along with a JSON based file that contains metadata about the image.  This metadata included filenames, dimensions, configuration information and pixel histogram information.
        Given that some systems may be limited in their graphical processing power, down sampling of the image resolution was added to the data processing layer.  Whenever an image is processed by the server, the data points are reduced 3 times and for each reduction a PNG is saved off and entry made into the manifest file.  The reductions occur by selecting an octet of the pixels and finding an average location and value.  This produces images that are 1/8, 1/64 and 1/512 the size and dimensions of the original image scan.
        Down sampling the image provides two direct benefits.


\subsection{Web Visualization}

\section{Conclusions}

%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{sigproc}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns
\appendix
%Appendix A
\section{}

% This next section command marks the start of
% Appendix B, and does not continue the present hierarchy

\balancecolumns
% That's all folks!
\end{document}
